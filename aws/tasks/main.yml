# (c) 2016 DataNexus Inc.  All Rights Reserved.
#
# Launch an AMI
---
- name: Retrieve default VPC ID
  local_action:
    module: ec2_vpc_net_facts
    region: "{{ region }}"
    filters:
      cidr_block: "{{ cidr_block }}"
  register: specified_vpc
   
- name: retrieving {{ private_subnet }} ID for {{ cidr_block }} in {{ cloud }} {{ region }}
  local_action:
    module: ec2_vpc_subnet_facts
    region: "{{ region }}"
    filters:
      cidr_block: "{{ interface_subnet }}"
  register: interface_subnet_result
  when:
    - interface_subnet is defined

- set_fact:
    interface_subnet_id: "{{ interface_subnet_result.subnets.0.id }}"
  when:
    - interface_subnet_result.skipped is not defined

- block:    
  - name: searching for CentOS 7 AMI for your region
    ec2_ami_find:
      name: "CentOS Linux 7 x86_64*"
      region: "{{ region }}"
      owner: 679593333241
      virtualization_type: hvm
      sort: name
      sort_order: descending
      sort_end: 1
    register: amis_found

  - set_fact:
      ami: "{{ amis_found.results[0].ami_id }}"
  when:
    - ami is not defined

- name: creating postgresql security group
  local_action:
    module: ec2_group
    name: "{{ project }}_postgresql"
    description: "postgresql ingress and unrestricted egress rules (ansible)"
    vpc_id: "{{ specified_vpc.vpcs.0.id }}"
    region: "{{ region }}"
    rules:
      - proto: tcp
        from_port: 22
        to_port: 22
        cidr_ip: "{{ interface_subnet }}"
      - proto: tcp
        from_port: 5432
        to_port: 5432
        cidr_ip: "{{ interface_subnet }}"
    rules_egress:
      # Allow all outbound
      - proto: all
        cidr_ip: 0.0.0.0/0
  register: sg_postgresql

- name: checking {{ region }}-postgresql-private-key.pem
  stat: path="./{{ region }}-postgresql-private-key.pem"
  register: existing_key

- name: generating public key from {{ region }}-postgresql-private-key.pem
  command: "/usr/bin/ssh-keygen -f {{ region }}-postgresql-private-key.pem -y"
  register: public_key_from_pem
  when: existing_key.stat.exists == True
    
- name: using existing {{ region }}-postgresql
  ec2_key:
    region: "{{ region }}"
    state: present
    name: "{{ region }}-postgresql"
    key_material: "{{ public_key_from_pem.stdout }}" 
  register: old_keypair
  when: existing_key.stat.exists == True

- set_fact: keypair="{{ old_keypair }}"
  when: existing_key.stat.exists == True

- name: creating {{ region}}-postgresql
  ec2_key:
    name: "{{ region }}-postgresql"
    region: "{{ region }}"
  register: new_keypair
  when: existing_key.stat.exists == False

- set_fact: keypair="{{ new_keypair }}"
  when: existing_key.stat.exists == False

- name: saving {{ region }}-postgresql
  copy:
    dest: "./{{ keypair.key.name }}-private-key.pem"
    content: "{{ keypair.key.private_key }}"
    mode: 0400
  when:
    - existing_key.stat.exists == False
    - keypair.changed

# always boot a single postgresql server
- name: setting count to single node
  set_fact:
    count: 1 
 
# the math is overkill, but it's useful if we want to get more complicated
- name: configuring instance count based on replica
  set_fact:
    count: "{{ count | int * 2 }}" 
  when:
    - replica

- name: launch AMI
  ec2:
    key_name: "{{ keypair.key.name }}"
    group_id: "{{ sg_postgresql.group_id }}"
    instance_type: "{{ type }}"
    image: "{{ ami }}"
    vpc_subnet_id: "{{ interface_subnet_id }}"
    region: "{{ region }}"
    assign_public_ip: yes
    wait: true
    exact_count: "{{ count }}"
    count_tag:
      Name: "{{ project }}_postgresql"
      Tenant: "{{ tenant }}"
      Project: "{{ project }}"
      Cloud: "{{ cloud }}"
      Domain: "{{ domain }}"
      Application: postgresql
      Cluster: "{{ cluster | default ('a') }}"
      Role: "{{ role | default ('none') }}"
      Dataflow: "{{ dataflow | default ('none') }}"
    instance_tags:
      Name: "{{ project }}_postgresql"
      Tenant: "{{ tenant }}"
      Project: "{{ project }}"
      Cloud: "{{ cloud }}"
      Domain: "{{ domain }}"
      Application: postgresql
      Cluster: "{{ cluster | default ('a') }}"
      Role: "{{ role | default ('none') }}"
      Dataflow: "{{ dataflow | default ('none') }}"
    ebs_optimized: false
    volumes:
      - device_name: /dev/sda1
        volume_type: gp2
        volume_size: "{{ root_volume }}"
        delete_on_termination: true
      - device_name: /dev/xvdb
        volume_type: gp2
        volume_size: "{{ data_volume }}"
        delete_on_termination: true
        encrypted: true
  register: ec2

# obviously this only works when we have a matched pair
- block:
  - name: ensuring postgresql master is tagged as such
    ec2_tag:
      region: "{{ region }}"
      resource: "{{ ec2.instances.0.id }}"
      state: present
      tags:
        Role: master

  - name: ensuring postgresql replica is tagged as such
    ec2_tag:
      region: "{{ region }}"
      resource: "{{ ec2.instances.1.id }}"
      state: present
      tags:
        Role: replica
  when:
    - not ec2|skipped and ec2.changed and ec2.instances|length > 0
    - replica
    
- name: building ansible host group of private IPs
  add_host: hostname="{{ item.private_ip }}" groups=postgresql ansible_ssh_private_key_file="./{{ keypair.key.name }}-private-key.pem" ec2_id="{{ item.id }}"
  with_items: "{{ ec2.instances }}"
  when:
    - not ec2 | skipped and ec2.changed and ec2.instances | length > 0

# wait_for doesn't work with a proxy, so we need to ssh and check output
- name: waiting for {{ item }} with {{ keypair.key.name }}-private-key.pem"
  local_action: shell /bin/sleep 60 && /usr/bin/ssh -i "./{{ keypair.key.name }}-private-key.pem" "{{ user }}"@"{{ item }}" echo DataNexus
  register: output
  retries: 4
  delay: 15
  until: output.stdout.find('DataNexus') != -1
  with_items: "{{ groups.postgresql }}"
  when:
    - not ec2|skipped and ec2.changed and ec2.instances|length > 0